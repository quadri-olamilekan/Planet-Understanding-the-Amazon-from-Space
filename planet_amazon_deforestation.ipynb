{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "planet_amazon_deforestation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOumM97eb30drGSeIcp07Uo"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7ChL6shBvh6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "import os\n",
        "import tarfile"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyxgt4L_Bxzk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://stackoverflow.com/questions/25010369/wget-curl-large-file-from-google-drive/25033499#25033499\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    def get_confirm_token(response):\n",
        "        for key, value in response.cookies.items():\n",
        "            if key.startswith('download_warning'):\n",
        "                return value\n",
        "\n",
        "        return None\n",
        "\n",
        "    def save_response_content(response, destination):\n",
        "        CHUNK_SIZE = 32768\n",
        "\n",
        "        with open(destination, \"wb\") as f:\n",
        "            for chunk in response.iter_content(CHUNK_SIZE):\n",
        "                if chunk: # filter out keep-alive new chunks\n",
        "                    f.write(chunk)\n",
        "\n",
        "    URL = \"https://drive.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "    save_response_content(response, destination)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRPyNbwrB1-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "destination = '../data.tar.gz'\n",
        "file_id = '1QkBngulbKYSyYgGeawM9TYfnfAVv4Chl'\n",
        "if not os.path.isfile(destination):\n",
        "    download_file_from_google_drive(file_id, destination)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ckqt56tYB9yn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_tar = tarfile.open('../data.tar.gz')\n",
        "my_tar.extractall('../')\n",
        "my_tar.close()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wp677Sw_CAW8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "4acdb786-4096-4e19-b0cd-312e3c914194"
      },
      "source": [
        "print('# File sizes')\n",
        "p = '../data'\n",
        "for f in os.listdir(p):\n",
        "    if not os.path.isdir(p+'/'+ f):\n",
        "        print (f.ljust(30) + str(round(os.path.getsize(p+'/'+ f) / 1000000, 2)) + 'MB')\n",
        "    else:\n",
        "        sizes = [os.path.getsize(p +'/'+f + '/'+x)/1000000 for x in os.listdir(p+'/'+f)]\n",
        "        print(f.ljust(30) + str(round(sum(sizes), 2)) + 'MB' + '({} files)'.format(len(sizes)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# File sizes\n",
            "models                        1939.14MB(6 files)\n",
            "densenet169.pkl               57.77MB\n",
            "resnet101.pkl                 179.1MB\n",
            "resnet152.pkl                 241.92MB\n",
            "train_v2.csv                  1.43MB\n",
            "test_labels.csv               2.35MB\n",
            "train-jpg                     634.68MB(40479 files)\n",
            "resnet50.pkl                  102.86MB\n",
            "test-jpg                      958.88MB(61191 files)\n",
            "densenet121.pkl               32.64MB\n",
            "submissions                   16.89MB(7 files)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be2uyE_eZtxl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import division\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Flatten, merge\n",
        "from keras.layers import Input, Activation, Dense, Flatten\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D, AveragePooling2D\n",
        "#from multi_gpu import make_parallel #Available here https://github.com/kuza55/keras-extras/blob/master/utils/multi_gpu.py\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras import backend as K\n",
        "import os\n",
        "from sklearn.utils import shuffle\n",
        "import random\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from sklearn.metrics import fbeta_score\n",
        "from keras.optimizers import Adam, SGD\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 1\""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MYhzZrKawpw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fbeta_loss(y_true, y_pred):\n",
        "    beta_squared = 4\n",
        "\n",
        "    tp = K.sum(y_true * y_pred) + K.epsilon()\n",
        "    fp = K.sum(y_pred) - tp\n",
        "    fn = K.sum(y_true) - tp\n",
        "\n",
        "    precision = tp / (tp + fp)\n",
        "    recall = tp / (tp + fn)\n",
        "\n",
        "    result = 1 - (beta_squared + 1) * (precision * recall) / (beta_squared * precision + recall + K.epsilon())\n",
        "\n",
        "    return result"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDgdAVcqa5c3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fbeta_score_K(y_true, y_pred):\n",
        "    beta_squared = 4\n",
        "\n",
        "    tp = K.sum(y_true * y_pred) + K.epsilon()\n",
        "    fp = K.sum(y_pred) - tp\n",
        "    fn = K.sum(y_true) - tp\n",
        "\n",
        "    precision = tp / (tp + fp)\n",
        "    recall = tp / (tp + fn)\n",
        "\n",
        "    result = (beta_squared + 1) * (precision * recall) / (beta_squared * precision + recall + K.epsilon())\n",
        "\n",
        "    return result"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddSYAdhSbBke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rotate(img):\n",
        "    rows = img.shape[0]\n",
        "    cols = img.shape[1]\n",
        "    angle = np.random.choice((10, 20, 30))#, 40, 50, 60, 70, 80, 90))\n",
        "    rotation_M = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, 1)\n",
        "    img = cv2.warpAffine(img, rotation_M, (cols, rows))\n",
        "    return img"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2-RxxSfbGSD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rotate_bound(image, size):\n",
        "    #credits http://www.pyimagesearch.com/2017/01/02/rotate-images-correctly-with-opencv-and-python/\n",
        "    (h, w) = image.shape[:2]\n",
        "    (cX, cY) = (w // 2, h // 2)\n",
        "\n",
        "    angle = np.random.randint(10,180)\n",
        "\n",
        "    M = cv2.getRotationMatrix2D((cX, cY), -angle, 1.0)\n",
        "    cos = np.abs(M[0, 0])\n",
        "    sin = np.abs(M[0, 1])\n",
        "\n",
        "    # compute the new bounding dimensions of the image\n",
        "    nW = int((h * sin) + (w * cos))\n",
        "    nH = int((h * cos) + (w * sin))\n",
        "\n",
        "    # adjust the rotation matrix to take into account translation\n",
        "    M[0, 2] += (nW / 2) - cX\n",
        "    M[1, 2] += (nH / 2) - cY\n",
        "\n",
        "    output = cv2.resize(cv2.warpAffine(image, M, (nW, nH)), (size, size))\n",
        "    return output"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNB8zUSQbPp5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def perspective(img):\n",
        "    rows = img.shape[0]\n",
        "    cols = img.shape[1]\n",
        "\n",
        "    shrink_ratio1 = np.random.randint(low=85, high=110, dtype=int) / 100\n",
        "    shrink_ratio2 = np.random.randint(low=85, high=110, dtype=int) / 100\n",
        "\n",
        "    zero_point = rows - np.round(rows * shrink_ratio1, 0)\n",
        "    max_point_row = np.round(rows * shrink_ratio1, 0)\n",
        "    max_point_col = np.round(cols * shrink_ratio2, 0)\n",
        "\n",
        "    src = np.float32([[zero_point, zero_point], [max_point_row-1, zero_point], [zero_point, max_point_col+1], [max_point_row-1, max_point_col+1]])\n",
        "    dst = np.float32([[0, 0], [rows, 0], [0, cols], [rows, cols]])\n",
        "\n",
        "    perspective_M = cv2.getPerspectiveTransform(src, dst)\n",
        "\n",
        "    img = cv2.warpPerspective(img, perspective_M, (cols,rows))#, borderValue=mean_pix)\n",
        "    return img"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9sSroqJbcEZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def shift(img):\n",
        "    rows = img.shape[0]\n",
        "    cols = img.shape[1]\n",
        "\n",
        "    shift_ratio1 = (random.random() * 2 - 1) * np.random.randint(low=3, high=15, dtype=int)\n",
        "    shift_ratio2 = (random.random() * 2 - 1) * np.random.randint(low=3, high=15, dtype=int)\n",
        "\n",
        "    shift_M = np.float32([[1,0,shift_ratio1], [0,1,shift_ratio2]])\n",
        "    img = cv2.warpAffine(img, shift_M, (cols, rows))#, borderValue=mean_pix)\n",
        "    return img"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBWOmUhDbiJ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_generator_train(zip_list, img_size, batch_size, is_train=True, shuffle=True):\n",
        "    number_of_batches = np.ceil(len(zip_list) / batch_size)\n",
        "    if shuffle == True:\n",
        "        random.shuffle(zip_list)\n",
        "    counter = 0\n",
        "    while True:\n",
        "        if shuffle == True:\n",
        "            random.shuffle(zip_list)\n",
        "\n",
        "        batch_files = zip_list[batch_size*counter:batch_size*(counter+1)]\n",
        "        image_list = []\n",
        "        mask_list = []\n",
        "\n",
        "        for file, mask in batch_files:\n",
        "\n",
        "            image = cv2.resize(cv2.imread(file), (img_size,img_size)) / 255.\n",
        "            image = image[:, :, [2, 1, 0]] - mean_pix\n",
        "\n",
        "            rnd_flip = np.random.randint(2, dtype=int)\n",
        "            rnd_rotate = np.random.randint(2, dtype=int)\n",
        "            rnd_zoom = np.random.randint(2, dtype=int)\n",
        "            rnd_shift = np.random.randint(2, dtype=int)\n",
        "\n",
        "            if (rnd_flip == 1) & (is_train == True):\n",
        "                rnd_flip = np.random.randint(3, dtype=int) - 1\n",
        "                image = cv2.flip(image, rnd_flip)\n",
        "\n",
        "            if (rnd_rotate == 1) & (is_train == True):\n",
        "                image = rotate_bound(image, img_size)\n",
        "\n",
        "            if (rnd_zoom == 1) & (is_train == True):\n",
        "                image = perspective(image)\n",
        "\n",
        "            if (rnd_shift == 1) & (is_train == True):\n",
        "                image = shift(image)\n",
        "\n",
        "            image_list.append(image)\n",
        "            mask_list.append(mask)\n",
        "\n",
        "        counter += 1\n",
        "        image_list = np.array(image_list)\n",
        "        mask_list = np.array(mask_list)\n",
        "\n",
        "        yield (image_list, mask_list)\n",
        "\n",
        "        if counter == number_of_batches:\n",
        "            if shuffle == True:\n",
        "                random.shuffle(zip_list)\n",
        "            counter = 0\n",
        "\n",
        "def batch_generator_test(zip_list, img_size, batch_size, shuffle=True):\n",
        "    number_of_batches = np.ceil(len(zip_list)/batch_size)\n",
        "    print(len(zip_list), number_of_batches)\n",
        "    counter = 0\n",
        "    if shuffle:\n",
        "        random.shuffle(zip_list)\n",
        "    while True:\n",
        "        batch_files = zip_list[batch_size*counter:batch_size*(counter+1)]\n",
        "        image_list = []\n",
        "        mask_list = []\n",
        "\n",
        "        for file, mask in batch_files:\n",
        "\n",
        "            image = cv2.resize(cv2.imread(file), (img_size, img_size))\n",
        "            image = image[:, :, [2, 1, 0]] - mean_pix\n",
        "            image_list.append(image)\n",
        "            mask_list.append(mask)\n",
        "\n",
        "        counter += 1\n",
        "        image_list = np.array(image_list)\n",
        "        mask_list = np.array(mask_list)\n",
        "\n",
        "        yield (image_list, mask_list)\n",
        "\n",
        "        if counter == number_of_batches:\n",
        "            random.shuffle(zip_list)\n",
        "            counter = 0\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeYras_Rb1NU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_generator(files, img_size, batch_size):\n",
        "    number_of_batches = np.ceil(len(files) / batch_size)\n",
        "    print(len(files), number_of_batches)\n",
        "    counter = 0\n",
        "    int_counter = 0\n",
        "\n",
        "    while True:\n",
        "            beg = batch_size * counter\n",
        "            end = batch_size * (counter + 1)\n",
        "            batch_files = files[beg:end]\n",
        "            image_list = []\n",
        "\n",
        "            for file in batch_files:\n",
        "                int_counter += 1\n",
        "                image = cv2.resize(cv2.imread(file), (img_size, img_size))\n",
        "                image = image[:, :, [2, 1, 0]] - mean_pix\n",
        "\n",
        "                rnd_flip = np.random.randint(2, dtype=int)\n",
        "                rnd_rotate = np.random.randint(2, dtype=int)\n",
        "                rnd_zoom = np.random.randint(2, dtype=int)\n",
        "                rnd_shift = np.random.randint(2, dtype=int)\n",
        "\n",
        "                if rnd_flip == 1:\n",
        "                    rnd_flip = np.random.randint(3, dtype=int) - 1\n",
        "                    image = cv2.flip(image, rnd_flip)\n",
        "\n",
        "                if rnd_rotate == 1:\n",
        "                    image = rotate_bound(image, img_size)\n",
        "\n",
        "                if rnd_zoom == 1:\n",
        "                    image = perspective(image)\n",
        "\n",
        "                if rnd_shift == 1:\n",
        "                    image = shift(image)\n",
        "\n",
        "                image_list.append(image)\n",
        "\n",
        "            counter += 1\n",
        "\n",
        "            image_list = np.array(image_list)\n",
        "\n",
        "            yield (image_list)\n",
        "\n",
        "\n",
        "def f2_score(y_true, y_pred):\n",
        "    y_true, y_pred, = np.array(y_true), np.array(y_pred)\n",
        "    score = fbeta_score(y_true, y_pred, beta=2, average='samples')\n",
        "    return score"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAg1GzQNcEkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GLOBAL_PATH = '../data/'\n",
        "TRAIN_FOLDER = '../data/train-jpg/'\n",
        "TEST_FOLDER = '../data/test-jpg/' \n",
        "F_CLASSES = GLOBAL_PATH + 'train_v2.csv'"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UUwXkrRe3rj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_csv(F_CLASSES)\n",
        "df_test = pd.read_csv(GLOBAL_PATH + 'test_labels.csv')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZ_YV1WkfB7X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = ['blow_down',\n",
        "          'bare_ground',\n",
        "          'conventional_mine',\n",
        "          'blooming',\n",
        "          'cultivation',\n",
        "          'artisinal_mine',\n",
        "          'haze',\n",
        "          'primary',\n",
        "          'slash_burn',\n",
        "          'habitation',\n",
        "          'clear',\n",
        "          'road',\n",
        "          'selective_logging',\n",
        "          'partly_cloudy',\n",
        "          'agriculture',\n",
        "          'water',\n",
        "          'cloudy']"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4kTDFLnfHCs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_map = {'agriculture': 14,\n",
        "             'artisinal_mine': 5,\n",
        "             'bare_ground': 1,\n",
        "             'blooming': 3,\n",
        "             'blow_down': 0,\n",
        "             'clear': 10,\n",
        "             'cloudy': 16,\n",
        "             'conventional_mine': 2,\n",
        "             'cultivation': 4,\n",
        "             'habitation': 9,\n",
        "             'haze': 6,\n",
        "             'partly_cloudy': 13,\n",
        "             'primary': 7,\n",
        "             'road': 11,\n",
        "             'selective_logging': 12,\n",
        "             'slash_burn': 8,\n",
        "             'water': 15}"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZH7GuBCfTT9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "flatten = lambda l: [item for sublist in l for item in sublist]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eucCLQ78fYcK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = []\n",
        "x_test = []\n",
        "y_train = []"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eWz-rQ-fhTB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "c66d4542-003c-4da3-bed7-419faa583ad9"
      },
      "source": [
        "for f, tags in tqdm(df_train.values, miniters=1000):\n",
        "    img = TRAIN_FOLDER + '{}.jpg'.format(f)\n",
        "    targets = np.zeros(17)\n",
        "    for t in tags.split(' '):\n",
        "        targets[label_map[t]] = 1\n",
        "    x_train.append(img)\n",
        "    y_train.append(targets)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40479/40479 [00:00<00:00, 281279.64it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOQRkd3ifner",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_holdout, y_train, y_holdout = x_train[3000:-1], x_train[:3000], y_train[3000:-1], y_train[:3000]\n",
        "\n",
        "x_train, y_train = shuffle(x_train, y_train, random_state = 24)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjjP9IbAf-Gf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "453f8ec1-0a89-4e2c-aecd-90bc6076fc8f"
      },
      "source": [
        "part = 0.85\n",
        "split = int(round(part*len(y_train)))\n",
        "x_train, x_valid, y_train, y_valid = x_train[:split], x_train[split:], y_train[:split], y_train[split:]\n",
        "print('x tr: ', len(x_train))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x tr:  31856\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcTNajQigOPD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "36c89cbf-472d-48c6-fe9a-68471c058cb2"
      },
      "source": [
        "#define callbacks\n",
        "callbacks = [ModelCheckpoint('amazon_2007.hdf5', monitor='val_loss', save_best_only=True, verbose=2, save_weights_only=False),\n",
        "             ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, verbose=1, mode='auto', epsilon=0.0001, cooldown=0, min_lr=0.0000001),\n",
        "             EarlyStopping(monitor='val_loss', patience=5, verbose=0)]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iClkRYADgaFD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH = 128\n",
        "IMG_SIZE = 224\n",
        "mean_pix = np.array([102.9801, 115.9465, 122.7717]) #It is BGR"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qa_aB2Sygh1a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications import ResNet50"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4EaXwcpgmPB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "40e819df-221b-4a71-feaf-fe853ea38ec8"
      },
      "source": [
        "#Compile model and set non-top layets non-trainable (warm-up)\n",
        "base_model = ResNet50(include_top=False, input_shape=(IMG_SIZE,IMG_SIZE,3), pooling='avg', weights='imagenet')\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = Dense(2048, activation='relu')(x)\n",
        "x = Dropout(0.25)(x)\n",
        "output = Dense(17, activation='sigmoid')(x)\n",
        "\n",
        "optimizer = Adam(0.001, decay=0.0003)\n",
        "model = Model(inputs=base_model.inputs, outputs=output)\n",
        "\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy', fbeta_score_K])\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZzhBevhkGV1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit_generator(generator=batch_generator_train(list(zip(x_train, y_train)), IMG_SIZE, BATCH),\n",
        "                          steps_per_epoch=np.ceil(len(x_train)/BATCH),\n",
        "                          epochs=1,\n",
        "                          verbose=1,\n",
        "                          validation_data=batch_generator_train(list(zip(x_valid, y_valid)), IMG_SIZE, 16),\n",
        "                          validation_steps=np.ceil(len(x_valid)/16),\n",
        "                          callbacks=callbacks,\n",
        "                          initial_epoch=0)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_AhuvCzsACz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Compile model and set all layers trainable\n",
        "from keras import optimizers\n",
        "optimizer = optimizers.Adam(0.0001, decay=0.00000001)\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy', fbeta_score_K])\n",
        "model.load_weights('amazon_2007.hdf5', by_name=True)\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlKdqQOFtq4H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH = 32\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy', fbeta_score_K])\n",
        "model.fit_generator(generator=batch_generator_train(list(zip(x_train, y_train)), IMG_SIZE, BATCH),\n",
        "                          steps_per_epoch=np.ceil(len(x_train)/BATCH),\n",
        "                          epochs=50,\n",
        "                          verbose=1,\n",
        "                          validation_data=batch_generator_train(list(zip(x_valid, y_valid)), IMG_SIZE, 16),\n",
        "                          validation_steps=np.ceil(len(x_valid)/16),\n",
        "                          callbacks=callbacks,\n",
        "                          initial_epoch=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkwkReDf_ugp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights('amazon_2007.hdf5')"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXeon1Ac_2Qm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "ed16e059-dc5b-48ab-ef17-b099f2766907"
      },
      "source": [
        "x_val = []\n",
        "y_val = []\n",
        "x_hld = []\n",
        "y_hld = []\n",
        "x_test = []\n",
        "y_test = []\n",
        "\n",
        "for f, tags in tqdm(list(zip(x_valid, y_valid)), miniters=1000):\n",
        "    y_val.append(tags) "
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5622/5622 [00:00<00:00, 1178370.75it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvsgI7tgCjXf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "5038d265-c65c-4785-f8d4-13e44eb3071f"
      },
      "source": [
        "p_valid = model.predict_generator(batch_generator_test(list(zip(x_valid, y_valid)), IMG_SIZE, 8, shuffle=False), steps=np.ceil(len(x_valid)/8))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-38-6e11e091f204>:1: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.predict, which supports generators.\n",
            "5622 703.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vSy0bLwE7HX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "b654760f-2e68-4557-eff5-59cd01e98838"
      },
      "source": [
        "print('val_set: ', fbeta_score(np.array(y_val), np.array(p_valid) > 0.2, beta=2, average='samples'))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "val_set:  0.4694372408764788\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpPDF29hFEMl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def optimise_f2_thresholds(y, p, verbose=True, resolution=100):\n",
        "    #credits https://www.kaggle.com/c/planet-understanding-the-amazon-from-space/discussion/32475\n",
        "  def mf(x):\n",
        "    p2 = np.zeros_like(p)\n",
        "    for i in range(17):\n",
        "      p2[:, i] = (p[:, i] > x[i]).astype(np.int)\n",
        "    score = fbeta_score(y, p2, beta=2, average='samples')\n",
        "    return score\n",
        "\n",
        "  x = [0.2]*17\n",
        "  for i in range(17):\n",
        "    best_i2 = 0\n",
        "    best_score = 0\n",
        "    for i2 in range(resolution):\n",
        "      i2 /= resolution\n",
        "      x[i] = i2\n",
        "      score = mf(x)\n",
        "      if score > best_score:\n",
        "        best_i2 = i2\n",
        "        best_score = score\n",
        "    x[i] = best_i2\n",
        "    if verbose:\n",
        "      print(i, best_i2, best_score)\n",
        "\n",
        "  return x"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCmMIbbwFIDG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "f5d7035c-7a15-406a-beac-27b178291928"
      },
      "source": [
        "X = optimise_f2_thresholds(np.array(y_val), np.array(p_valid))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.01 0.4694372408764788\n",
            "1 0.07 0.4694372408764788\n",
            "2 0.06 0.4694372408764788\n",
            "3 0.01 0.4694372408764788\n",
            "4 0.16 0.4694372408764788\n",
            "5 0.99 0.4699491249625953\n",
            "6 0.01 0.4699491249625953\n",
            "7 0.0 0.4699491249625953\n",
            "8 0.01 0.4699491249625953\n",
            "9 0.22 0.46996052705510727\n",
            "10 0.0 0.6637152918176321\n",
            "11 0.73 0.6637759302187187\n",
            "12 0.01 0.6637759302187187\n",
            "13 0.99 0.6725717809587499\n",
            "14 0.0 0.7004998983194927\n",
            "15 0.99 0.7092211437605831\n",
            "16 0.01 0.7092211437605831\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_mcpFgbGIAH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "e3139818-79d1-47c8-f88b-f99424a6af7f"
      },
      "source": [
        "for f, tags in tqdm(list(zip(x_holdout, y_holdout)), miniters=1000):\n",
        "    img = cv2.resize(cv2.imread(f), (IMG_SIZE, IMG_SIZE))\n",
        "    x_hld.append(img)\n",
        "    y_hld.append(tags)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3000/3000 [00:06<00:00, 441.56it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taty1s5AGiqC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "333bc915-c486-4ebf-9a48-25952ab1eb02"
      },
      "source": [
        "if len(x_holdout) % 2 > 0:\n",
        "    x_hld.append(x_hld[0])\n",
        "    y_hld.append(y_hld[0])\n",
        "\n",
        "x_hld = np.array(x_hld, np.float16)\n",
        "\n",
        "p_valid = model.predict(x_hld, batch_size=28, verbose=2)\n",
        "print('holdout set: ', f2_score(np.array(y_hld), np.array(p_valid) > 0.2))\n",
        "print('holdout set w/ thresh: ', f2_score(np.array(y_hld), np.array(p_valid) > 0.19))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0114s vs `on_predict_batch_end` time: 0.0692s). Check your callbacks.\n",
            "108/108 - 9s\n",
            "holdout set:  0.47312073788907216\n",
            "holdout set w/ thresh:  0.4732788762906316\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cl1G1PpFGr5P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "cbbece3c-278d-4fe1-b243-062801d3b2c2"
      },
      "source": [
        "for f, tags in tqdm(df_test.values, miniters=1000):\n",
        "    img = TEST_FOLDER + '{}.jpg'.format(f)\n",
        "    x_test.append(img)\n",
        "\n",
        "batch_size_test = 32\n",
        "len_test = len(x_test)\n",
        "x_tst = []\n",
        "yfull_test = []"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 61191/61191 [00:00<00:00, 620752.04it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOR9NBV8G3wF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TTA_steps = 30\n",
        "\n",
        "for k in range(0, TTA_steps):\n",
        "    print(k)\n",
        "    probs = model.predict_generator(predict_generator(x_test,IMG_SIZE,batch_size_test), steps=np.ceil(len(x_test)/batch_size_test),verbose=1)\n",
        "    yfull_test.append(probs)\n",
        "    k += 1\n",
        "\n",
        "result = np.array(yfull_test[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vy1hsd76HBXX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(1, TTA_steps):\n",
        "    result += np.array(yfull_test[i])\n",
        "result /= TTA_steps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CiVkdSoUJp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res = pd.DataFrame(result, columns=labels)\n",
        "preds = []"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6LoBOdtUSok",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "1d983891-6d48-4576-b80a-146fe841ad71"
      },
      "source": [
        "for i in tqdm(range(res.shape[0]), miniters=1000):\n",
        "    a = res.loc[[i]] \n",
        "    a = a.apply(lambda x: x > X, axis=1)\n",
        "    a = a.transpose()\n",
        "    a = a.loc[a[i] == True]\n",
        "    ' '.join(list(a.index))\n",
        "    preds.append(' '.join(list(a.index)))"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 61191/61191 [04:02<00:00, 252.61it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_vQXPjhWAcG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "84b5b690-189b-4ecd-ce82-4233b874e61a"
      },
      "source": [
        "print(len(preds))"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "61191\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Zzcd-FEWE6w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test['tags'] = preds\n",
        "df_test.to_csv('submission1.csv', index=False)"
      ],
      "execution_count": 130,
      "outputs": []
    }
  ]
}